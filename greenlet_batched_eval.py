# %%
import time
from typing import Any

import numpy as np
import scipy.optimize as so
from greenlet import greenlet

from benchmark_tensor_operations import TensorOperationsBenchmark

np.random.seed(42)


def fmin_l_bfgs_b_batched(func_and_grad_batch, xs0: np.ndarray, bounds: list[Any]) -> list[Any]:
    n, d = xs0.shape
    assert len(bounds) == n

    results: list[Any]
    results = [None] * n

    def run(i: int) -> None:
        def func(x: np.ndarray) -> tuple[float, np.ndarray]:
            assert x.shape == (d,)
            y, grad = greenlet.getcurrent().parent.switch(x)
            assert grad.shape == (d,)
            return y, grad

        results[i] = so.fmin_l_bfgs_b(
            func=func,
            x0=xs0[i],
            bounds=bounds[i],
            iprint=-1,  # é€”ä¸­çµŒéã‚’éè¡¨ç¤º
        )

    # æœ€åˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆåé›†
    xs = []
    greenlets = []
    for i in range(n):
        gl = greenlet(run)
        x = gl.switch(i)
        if x is None:  # ãã®greenletã¯çµ‚äº†æ¸ˆã¿ã§æ¬¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãªã—
            continue
        assert x.shape == (d,)
        xs.append(x)
        greenlets.append(gl)

    while len(xs) > 0:
        # ãƒãƒƒãƒè©•ä¾¡
        ys, grads = func_and_grad_batch(np.stack(xs))
        assert ys.shape == (len(xs),)
        assert grads.shape == (len(xs), d)

        # çµæœã®åˆ†é…ã¨æ¬¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆåé›†
        xs_next = []
        greenlets_next = []
        for j, gl in enumerate(greenlets):
            x = gl.switch((ys[j], grads[j]))
            if x is None:  # ãã®greenletã¯çµ‚äº†æ¸ˆã¿ã§æ¬¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãªã—
                continue
            assert x.shape == (d,)
            xs_next.append(x)
            greenlets_next.append(gl)
        xs = xs_next
        greenlets = greenlets_next

    return results


# %%
D = 50  # æ¬¡å…ƒ
SCALE = np.random.rand(D) * 10 + 1.0  # å„æ¬¡å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
N_LOCAL_SEARCH = 10
DIMENSION = D
BOUNDS = [(-5.0, 5.0) for _ in range(DIMENSION)]
STARTING_POINTS = np.array(
    [
        np.random.uniform(BOUNDS[0][0], BOUNDS[0][1], size=len(BOUNDS))
        for _ in range(N_LOCAL_SEARCH)
    ]
)
N_TRIALS = 300

t = TensorOperationsBenchmark(n_trials=N_TRIALS, dimension=DIMENSION, batch_size=N_LOCAL_SEARCH)
t_batched = TensorOperationsBenchmark(n_trials=N_TRIALS, dimension=DIMENSION, batch_size=1)


# %%
def func_and_grad(x: np.ndarray) -> tuple[float, np.ndarray]:
    # å·®ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã‚ˆã†ã«äººç‚ºçš„ã«sleepã‚’å…¥ã‚Œã‚‹
    t.execute()
    x = x * SCALE  # ã‚¹ã‚±ãƒ¼ãƒ«ã‚’ã‹ã‘ã‚‹
    return np.sum(x**2), 2 * x


# --- è©•ä¾¡å¯¾è±¡ã®é–¢æ•°ï¼ˆãƒãƒƒãƒå¯¾å¿œç‰ˆï¼‰ ---

# %%


def func_and_grad_batched(x_batch: np.ndarray) -> tuple[np.ndarray, np.ndarray]:
    """
    (N, D)å½¢çŠ¶ã®Nå€‹ã®ç‚¹xã‚’ãƒãƒƒãƒã§å—ã‘å–ã‚Šã€
    Nå€‹ã®é–¢æ•°å€¤ã¨(N, D)å½¢çŠ¶ã®å‹¾é…ã‚’è¿”ã™
    """
    # å®Ÿéš›ã®é‡ã„è¨ˆç®—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    x_batch = x_batch * SCALE  # ã‚¹ã‚±ãƒ¼ãƒ«ã‚’ã‹ã‘ã‚‹
    fvals = np.sum(x_batch**2, axis=1)
    grads = 2 * x_batch

    # å·®ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã‚ˆã†ã«äººç‚ºçš„ã«sleepã‚’å…¥ã‚Œã‚‹
    # ãƒãƒƒãƒã§è¨ˆç®—ã™ã‚‹ã¨90%ã®æ™‚é–“ã§è¨ˆç®—ã§ãã‚‹ã¨ä»®å®š
    # time.sleep(0.1 * len(x_batch) * 0.6)
    t_batched.execute()
    return fvals, grads


fvals, grads = func_and_grad_batched(np.random.rand(10, D))  # å‹•ä½œç¢ºèª
print(f"fvals: {fvals}")
print(f"grads shape: {grads.shape}")
# %%


if __name__ == "__main__":
    # Optimize Batch
    start = time.time()
    final_results = fmin_l_bfgs_b_batched(
        func_and_grad_batched, STARTING_POINTS, [BOUNDS] * N_LOCAL_SEARCH
    )
    elapsed = time.time() - start

    best_result = min(final_results, key=lambda r: r[1])
    print("\n" + "=" * 50)
    print("ğŸš€ Overall Best Result:")
    print(f"  Minimum function value: {best_result[1]:.6f}")
    print(f"  Elapsed time: {elapsed:3e} seconds")
    print(f"  Found at x: {best_result[0]}")
    print("=" * 50)

    # Optimize Sequentially
    best_fval = float("inf")
    best_x = None
    start = time.time()
    for i in range(N_LOCAL_SEARCH):
        min_x, min_f, info = so.fmin_l_bfgs_b(
            func=func_and_grad,
            x0=STARTING_POINTS[i],
            bounds=BOUNDS,
            iprint=-1,  # é€”ä¸­çµŒéã‚’éè¡¨ç¤º
        )
        # cast np.ndarray to float for
        min_f = min_f.item()
        print(f"  ğŸ‰ [Seq {i}] Finished. f(x) = {min_f:.4f}")
        if min_f < best_fval:
            best_fval = min_f
            best_x = min_x
    elapsed = time.time() - start

    print("\n" + "=" * 50)
    print("ğŸš€ Overall Best Result:")
    print(f"  Minimum function value: {best_fval:.6f}")
    print(f"  Found at x: {best_x}")
    print(f"  Elapsed time: {elapsed:3e} seconds")
    print("=" * 50)
